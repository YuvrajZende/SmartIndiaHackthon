@echo off
echo ðŸŒŠ Starting Ocean LLM - AI-Powered Ocean Data Analysis Platform
echo ================================================================

echo.
echo ðŸ“¦ Starting Backend Server...
cd backend
start "Ocean LLM Backend" cmd /k "python app.py"

echo.
echo â³ Waiting for backend to initialize...
timeout /t 3 /nobreak > nul

echo.
echo ðŸŽ¨ Starting Frontend Server...
cd ..\frontend
start "Ocean LLM Frontend" cmd /k "npm run dev"

echo.
echo âœ… Both servers are starting!
echo.
echo ðŸŒ Backend API: http://localhost:8000
echo ðŸ“š API Docs: http://localhost:8000/docs
echo ðŸŽ¨ Frontend: http://localhost:5173
echo.
echo ðŸ”‘ GEMINI_API_KEY is configured in config_keys.py
echo ðŸ“Š Visualizations will show real ocean data points and graphs
echo.
echo Press any key to exit this window...
pause > nul

